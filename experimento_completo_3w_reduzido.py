import numpy as np
import pandas as pd
from sklearn.ensemble import RandomForestClassifier, IsolationForest
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report
from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score
from sklearn.preprocessing import StandardScaler
from sklearn.neural_network import MLPClassifier
import xgboost as xgb
import shap
import matplotlib.pyplot as plt
import seaborn as sns
from collections import Counter
import warnings
import pickle
import os
from datetime import datetime
warnings.filterwarnings('ignore')

# Criar c√≥digo completo para o dataset 3W
# codigo_completo_3w =
# """
# Experimento Completo - Dataset 3W Petrobras
# Detec√ß√£o de Anomalias com RF, XGBoost, IF, MLP e Autoencoder
# ...
# """

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime
import warnings
import os
import pickle
from collections import Counter, defaultdict

# Bibliotecas ML
from sklearn.ensemble import RandomForestClassifier, IsolationForest
from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score
from sklearn.preprocessing import StandardScaler, RobustScaler
from sklearn.metrics import (accuracy_score, precision_score, recall_score, 
                           f1_score, roc_auc_score, classification_report,
                           confusion_matrix, roc_curve, auc)
from sklearn.neural_network import MLPClassifier
import xgboost as xgb

# Deep Learning
from tensorflow.keras.models import Model, Sequential
from tensorflow.keras.layers import Input, Dense, Dropout
from tensorflow.keras import regularizers
import tensorflow as tf

# Explicabilidade
import shap
import lime
import lime.lime_tabular

warnings.filterwarnings('ignore')
np.random.seed(42)
tf.random.set_seed(42)

print("="*80)
print("EXPERIMENTO DATASET 3W - PETROBRAS")
print("="*80)

# ==============================================================================
# 1. CARREGAMENTO E PREPARA√á√ÉO DOS DADOS
# ==============================================================================
import glob
import os

def load_3w_dataset():
    print("\n1. CARREGANDO DATASET 3W REAL...")

    base_path = r'C:\Users\rosej\Downloads\mestrado-master\mestrado-master\results_2_0\data'
    csv_files = glob.glob(os.path.join(base_path, '*', '*.csv'))

    print(f"‚úì Encontrados {len(csv_files)} arquivos CSV.")

    df_list = []
    for file in csv_files:
        try:
            df = pd.read_csv(file)  # usa separador padr√£o: v√≠rgula
            df['source_file'] = os.path.basename(file)
            df_list.append(df)
        except Exception as e:
            print(f"‚ö†Ô∏è Erro ao ler {file}: {e}")

    df = pd.concat(df_list, ignore_index=True)

    if 'class' not in df.columns:
        raise ValueError("Coluna 'class' n√£o encontrada no dataset.")

    if 'timestamp' in df.columns:
        df['timestamp'] = pd.to_datetime(df['timestamp'], errors='coerce')

    df['binary_class'] = (df['class'] > 0).astype(int)

    print(f"‚úì Dataset consolidado: {df.shape[0]} amostras")
    print(f"‚úì Colunas: {list(df.columns)}")

    return df

    return df



# def load_3w_dataset(path='3w_dataset/'):
#     """
#     Carrega o dataset 3W da Petrobras
#     Nota: O dataset precisa ser baixado de: https://github.com/ricardovvargas/3w_dataset
#     """
#     print("\\n1. CARREGANDO DATASET 3W...")
    
#     # Simula√ß√£o caso o dataset n√£o esteja dispon√≠vel localmente
#     # Em produ√ß√£o, substituir por pd.read_parquet() ou pd.read_csv() com os dados reais
#     print("‚ö†Ô∏è  Aten√ß√£o: Usando simula√ß√£o do dataset 3W para demonstra√ß√£o")
#     print("   Para usar dados reais, baixe de: https://github.com/ricardovvargas/3w_dataset")
    
#     # Caracter√≠sticas do dataset 3W real (baseado na documenta√ß√£o)
#     n_samples = 49996  # Dataset real tem milh√µes, reduzido para demo
#     n_features = 8     # P-PDG, P-TPT, T-TPT, P-MON-CKP, T-JUS-CKP, P-JUS-CKGL, QGL, class
    
#     # Vari√°veis do dataset 3W
#     feature_names = ['P-PDG', 'P-TPT', 'T-TPT', 'P-MON-CKP', 
#                     'T-JUS-CKP', 'P-JUS-CKGL', 'QGL']
    
#     # Simular dados com caracter√≠sticas similares ao 3W
#     # Classe 0: Normal (97%), Classes 1-8: Diferentes tipos de anomalias (3%)
#     normal_ratio = 0.97
#     n_normal = int(n_samples * normal_ratio)
#     n_anomalies = n_samples - n_normal
    
#     # Dados normais - distribui√ß√µes t√≠picas de sensores
#     X_normal = np.random.randn(n_normal, n_features-1)
#     X_normal[:, 0] *= 50 + 200    # P-PDG: press√£o ~200 ¬± 50
#     X_normal[:, 1] *= 30 + 150    # P-TPT: press√£o ~150 ¬± 30
#     X_normal[:, 2] *= 10 + 80     # T-TPT: temperatura ~80 ¬± 10
#     X_normal[:, 3] *= 20 + 100    # P-MON-CKP: press√£o ~100 ¬± 20
#     X_normal[:, 4] *= 5 + 70      # T-JUS-CKP: temperatura ~70 ¬± 5
#     X_normal[:, 5] *= 15 + 90     # P-JUS-CKGL: press√£o ~90 ¬± 15
#     X_normal[:, 6] *= 100 + 500   # QGL: vaz√£o ~500 ¬± 100
    
#     # Dados an√¥malos - 8 tipos diferentes de falhas
#     anomaly_types = 8
#     X_anomalies = []
#     y_anomalies = []
    
#     for anomaly_type in range(1, anomaly_types + 1):
#         n_type = n_anomalies // anomaly_types
#         X_anom = np.random.randn(n_type, n_features-1)
        
#         # Cada tipo de anomalia afeta diferentes sensores
#         if anomaly_type == 1:  # Falha de bomba
#             X_anom[:, [0, 1, 6]] *= 2  # Press√µes e vaz√£o afetadas
#         elif anomaly_type == 2:  # Obstru√ß√£o
#             X_anom[:, 6] *= 0.3  # Vaz√£o reduzida
#             X_anom[:, [0, 1]] *= 1.5  # Press√µes aumentadas
#         elif anomaly_type == 3:  # Vazamento
#             X_anom[:, [0, 1, 5]] *= 0.7  # Press√µes reduzidas
#         elif anomaly_type == 4:  # Falha de sensor
#             sensor_idx = np.random.randint(0, n_features-1)
#             X_anom[:, sensor_idx] = np.random.choice([0, 999, -999], size=n_type)
#         elif anomaly_type == 5:  # Temperatura anormal
#             X_anom[:, [2, 4]] *= 2  # Temperaturas elevadas
#         elif anomaly_type == 6:  # Cavita√ß√£o
#             X_anom[:, 6] += np.random.normal(0, 200, n_type)  # Vaz√£o inst√°vel
#         elif anomaly_type == 7:  # Golfada
#             X_anom[:, :] += np.random.normal(0, 50, (n_type, n_features-1))
#         else:  # Hidrato
#             X_anom[:, [0, 1, 5]] *= 1.3
#             X_anom[:, [2, 4]] *= 0.8
        
#         # Aplicar valores base
#         X_anom[:, 0] += 200
#         X_anom[:, 1] += 150
#         X_anom[:, 2] += 80
#         X_anom[:, 3] += 100
#         X_anom[:, 4] += 70
#         X_anom[:, 5] += 90
#         X_anom[:, 6] += 500
        
#         X_anomalies.append(X_anom)
#         y_anomalies.extend([anomaly_type] * n_type)
    
#     # Combinar dados
#     X_anomalies = np.vstack(X_anomalies)
#     X = np.vstack([X_normal, X_anomalies])
#     y = np.array([0] * n_normal + y_anomalies)
    
#     # Criar DataFrame
#     df = pd.DataFrame(X, columns=feature_names)
#     # Ajustar para n√∫mero real de linhas (X.shape[0])
#     df['timestamp'] = pd.date_range('2024-01-01', periods=X.shape[0], freq='T')
#     df['class'] = y
#     df['timestamp'] = pd.date_range('2024-01-01', periods=n_samples, freq='T')
#     df['well'] = np.random.choice(['WELL-001', 'WELL-002', 'WELL-003'], n_samples)
    
#     # Converter para problema bin√°rio (0: normal, 1: anomalia)
#     df['binary_class'] = (df['class'] > 0).astype(int)
    
#     print(f"‚úì Dataset carregado: {df.shape[0]} amostras, {df.shape[1]} colunas")
#     print(f"‚úì Classes: {df['class'].value_counts().to_dict()}")
#     print(f"‚úì Distribui√ß√£o bin√°ria: Normal={sum(df['binary_class']==0)}, Anomalia={sum(df['binary_class']==1)}")
    
#     return df

# ==============================================================================
# 2. PR√â-PROCESSAMENTO E FEATURE ENGINEERING
# ==============================================================================

def preprocess_data(df, test_size=0.3):
    """Pr√©-processamento completo dos dados"""
    print("\\n2. PR√â-PROCESSAMENTO DOS DADOS...")
    
    # Separar features e target
    feature_cols = ['P-PDG', 'P-TPT', 'T-TPT', 'P-MON-CKP', 
                   'T-JUS-CKP', 'P-JUS-CKGL', 'QGL']
    X = df[feature_cols].copy()
    y = df['binary_class'].values
    
    # Tratar valores ausentes (se houver)
    print(f"   - Valores ausentes: {X.isnull().sum().sum()}")
    X = X.fillna(X.median())
    
    # Detectar e tratar outliers extremos (m√©todo IQR)
    print("   - Tratando outliers extremos...")
    Q1 = X.quantile(0.25)
    Q3 = X.quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 3 * IQR
    upper_bound = Q3 + 3 * IQR
    
    # Clipar valores extremos
    for col in X.columns:
        X[col] = X[col].clip(lower=lower_bound[col], upper=upper_bound[col])
    
    # Feature Engineering - Estat√≠sticas
    print("   - Criando features estat√≠sticas...")
    X['mean_pressure'] = X[['P-PDG', 'P-TPT', 'P-MON-CKP', 'P-JUS-CKGL']].mean(axis=1)
    X['std_pressure'] = X[['P-PDG', 'P-TPT', 'P-MON-CKP', 'P-JUS-CKGL']].std(axis=1)
    X['mean_temp'] = X[['T-TPT', 'T-JUS-CKP']].mean(axis=1)
    X['pressure_ratio'] = X['P-PDG'] / (X['P-TPT'] + 1e-6)
    X['flow_pressure_ratio'] = X['QGL'] / (X['mean_pressure'] + 1e-6)
    
    # Normaliza√ß√£o com RobustScaler (melhor para outliers)
    scaler = RobustScaler()
    X_scaled = scaler.fit_transform(X)
    
    # Split estratificado
    X_train, X_test, y_train, y_test = train_test_split(
        X_scaled, y, test_size=test_size, random_state=42, stratify=y
    )
    
    print(f"‚úì Pr√©-processamento conclu√≠do")
    print(f"‚úì Features expandidas: {X.shape[1]} features")
    print(f"‚úì Train: {X_train.shape[0]} amostras, Test: {X_test.shape[0]} amostras")
    
    return X_train, X_test, y_train, y_test, scaler, X.columns.tolist()

# ==============================================================================
# 3. MODELOS DE MACHINE LEARNING
# ==============================================================================

def create_autoencoder(input_dim, encoding_dim=16):
    """Cria um autoencoder para detec√ß√£o de anomalias"""
    # Encoder
    input_layer = Input(shape=(input_dim,))
    encoded = Dense(64, activation='relu')(input_layer)
    encoded = Dropout(0.2)(encoded)
    encoded = Dense(32, activation='relu')(encoded)
    encoded = Dense(encoding_dim, activation='relu', 
                   activity_regularizer=regularizers.l1(1e-5))(encoded)
    
    # Decoder
    decoded = Dense(32, activation='relu')(encoded)
    decoded = Dropout(0.2)(decoded)
    decoded = Dense(64, activation='relu')(decoded)
    decoded = Dense(input_dim, activation='linear')(decoded)
    
    # Modelo completo
    autoencoder = Model(input_layer, decoded)
    autoencoder.compile(optimizer='adam', loss='mse')
    
    return autoencoder

def train_models(X_train, X_test, y_train, y_test):
    """Treina todos os modelos"""
    print("\\n3. TREINANDO MODELOS...")
    
    models = {}
    results = {}
    
    # 1. Random Forest
    print("\\n   3.1 Random Forest...")
    rf = RandomForestClassifier(
        n_estimators=100, 
        max_depth=10,
        min_samples_split=20,
        class_weight='balanced',
        random_state=42,
        n_jobs=-1
    )
    rf.fit(X_train, y_train)
    models['Random Forest'] = rf
    
    # 2. XGBoost
    print("   3.2 XGBoost...")
    xgb_model = xgb.XGBClassifier(
        n_estimators=100,
        max_depth=6,
        learning_rate=0.1,
        scale_pos_weight=sum(y_train==0)/sum(y_train==1),
        random_state=42,
        use_label_encoder=False,
        eval_metric='logloss'
    )
    xgb_model.fit(X_train, y_train)
    models['XGBoost'] = xgb_model
    
    # 3. Isolation Forest
    print("   3.3 Isolation Forest...")
    iso_forest = IsolationForest(
        n_estimators=100,
        contamination='auto',  # <== aqui est√° a corre√ß√£o
        random_state=42,
        n_jobs=-1
    )
    iso_forest.fit(X_train[y_train == 0])  # Treinar apenas com dados normais
    models['Isolation Forest'] = iso_forest
    
    # 4. MLP (Deep Learning)
    print("   3.4 MLP Neural Network...")
    mlp = MLPClassifier(
        hidden_layer_sizes=(100, 50, 25),
        activation='relu',
        solver='adam',
        alpha=0.001,
        batch_size=32,
        learning_rate='adaptive',
        max_iter=500,
        random_state=42,
        early_stopping=True,
        validation_fraction=0.1
    )
    mlp.fit(X_train, y_train)
    models['MLP'] = mlp
    
    # 5. Autoencoder
    print("   3.5 Autoencoder...")
    autoencoder = create_autoencoder(X_train.shape[1])
    
    # Treinar apenas com dados normais
    X_train_normal = X_train[y_train == 0]
    history = autoencoder.fit(
        X_train_normal, X_train_normal,
        epochs=50,
        batch_size=32,
        validation_split=0.1,
        verbose=0
    )
    models['Autoencoder'] = autoencoder
    
    print("\\n‚úì Todos os modelos treinados com sucesso!")
    
    return models

# ==============================================================================
# 4. AVALIA√á√ÉO E CROSS-VALIDATION
# ==============================================================================

def evaluate_models(models, X_train, X_test, y_train, y_test):
    """Avalia todos os modelos com m√©tricas e cross-validation"""
    print("\\n4. AVALIANDO MODELOS...")
    
    results = {}
    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
    
    for name, model in models.items():
        print(f"\\n   Avaliando {name}...")
        
        # Predi√ß√µes
        if name == 'Isolation Forest':
            # IF retorna -1 para anomalias, 1 para normal
            y_pred = model.predict(X_test)
            y_pred = (y_pred == -1).astype(int)
            y_scores = -model.score_samples(X_test)  # Scores negativos = anomalia
        elif name == 'Autoencoder':
            # Autoencoder usa erro de reconstru√ß√£o
            X_pred = model.predict(X_test)
            mse = np.mean((X_test - X_pred)**2, axis=1)
            threshold = np.percentile(mse, 95)  # Top 5% como anomalias
            y_pred = (mse > threshold).astype(int)
            y_scores = mse
        else:
            y_pred = model.predict(X_test)
            y_scores = model.predict_proba(X_test)[:, 1]
        
        # M√©tricas
        acc = accuracy_score(y_test, y_pred)
        prec = precision_score(y_test, y_pred, zero_division=0)
        rec = recall_score(y_test, y_pred)
        f1 = f1_score(y_test, y_pred)
        
        # AUC-ROC
        try:
            auc = roc_auc_score(y_test, y_scores)
        except:
            auc = 0.5
        
        # Cross-validation (apenas para modelos supervisionados)
        if name in ['Random Forest', 'XGBoost', 'MLP']:
            cv_scores = cross_val_score(model, X_train, y_train, cv=cv, scoring='f1')
            cv_mean = cv_scores.mean()
            cv_std = cv_scores.std()
        else:
            cv_mean = cv_std = 0
        
        results[name] = {
            'accuracy': acc,
            'precision': prec,
            'recall': rec,
            'f1_score': f1,
            'auc_roc': auc,
            'cv_f1_mean': cv_mean,
            'cv_f1_std': cv_std,
            'y_pred': y_pred,
            'y_scores': y_scores
        }
        
        print(f"      Accuracy: {acc:.4f}")
        print(f"      Precision: {prec:.4f}")
        print(f"      Recall: {rec:.4f}")
        print(f"      F1-Score: {f1:.4f}")
        print(f"      AUC-ROC: {auc:.4f}")
        if cv_mean > 0:
            print(f"      CV F1 (mean¬±std): {cv_mean:.4f}¬±{cv_std:.4f}")
    
    return results

# ==============================================================================
# 5. AN√ÅLISE DE EXPLICABILIDADE COM SHAP E LIME
# ==============================================================================

#def analyze_shap_stability(models, X_train, X_test, feature_names, n_iterations=30):
def analyze_shap_stability(models, X_train, X_test, y_train, feature_names, n_iterations=30):
    """Analisa a estabilidade das explica√ß√µes SHAP em m√∫ltiplas execu√ß√µes"""
    print("\\n5. AN√ÅLISE DE ESTABILIDADE DAS EXPLICA√á√ïES (30 itera√ß√µes)...")
    
    shap_results = {}
    
    for model_name in ['Random Forest', 'XGBoost']:
        if model_name not in models:
            continue
            
        print(f"\\n   Analisando {model_name}...")
        feature_importance_counts = defaultdict(int)
        feature_positions = defaultdict(list)
        all_shap_values = []
        
        for i in range(n_iterations):
            # Re-treinar modelo com seed diferente
            if model_name == 'Random Forest':
                model = RandomForestClassifier(
                    n_estimators=100, 
                    max_depth=10,
                    min_samples_split=20,
                    class_weight='balanced',
                    random_state=i,
                    n_jobs=-1
                )
            else:  # XGBoost
                model = xgb.XGBClassifier(
                    n_estimators=100,
                    max_depth=6,
                    learning_rate=0.1,
                    random_state=i,
                    use_label_encoder=False,
                    eval_metric='logloss'
                )
            
            model.fit(X_train, y_train)
            
            # Calcular SHAP values
            if model_name == 'Random Forest':
                explainer = shap.TreeExplainer(model)
            else:
                explainer = shap.TreeExplainer(model)
            
            shap_values = explainer.shap_values(X_test[:100])  # Subset para velocidade
            
            # Para modelos bin√°rios, pegar valores da classe positiva
            if isinstance(shap_values, list):
                shap_values = shap_values[1]
            
            all_shap_values.append(shap_values)
            
            # Import√¢ncia m√©dia absoluta
            feature_importance = np.abs(shap_values).mean(axis=0)
            
            # Top 5 features
            top_5_indices = np.argsort(feature_importance)[-5:][::-1]
                    
        for rank, idx in enumerate(top_5_indices):
            if isinstance(idx, (np.ndarray, list)):
                idx = int(idx[0])  # pega o primeiro elemento se for array/lista
            else:
                idx = int(idx)
            feature_importance_counts[feature_names[idx]] += 1
            feature_positions[feature_names[idx]].append(rank + 1)

            
            if (i + 1) % 10 == 0:
                print(f"      Itera√ß√£o {i+1}/{n_iterations} conclu√≠da")
        
        # Calcular estat√≠sticas
        shap_results[model_name] = {
            'feature_counts': dict(feature_importance_counts),
            'feature_positions': {k: np.mean(v) for k, v in feature_positions.items()},
            'all_shap_values': all_shap_values,
            'stability_score': len([f for f, c in feature_importance_counts.items() if c >= 15]) / 5
        }
        
        print(f"   ‚úì {model_name} - Score de estabilidade: {shap_results[model_name]['stability_score']:.2%}")
    
    return shap_results

def analyze_lime_isolation_forest(iso_forest, X_train, X_test, feature_names, n_iterations=30):
    """Analisa explica√ß√µes LIME para Isolation Forest"""
    print("\\n6. AN√ÅLISE LIME PARA ISOLATION FOREST...")
    
    # Preparar LIME
    explainer = lime.lime_tabular.LimeTabularExplainer(
        X_train,
        feature_names=feature_names,
        class_names=['Normal', 'Anomalia'],
        mode='classification'
    )
    
    # Fun√ß√£o de predi√ß√£o para LIME
    def predict_fn(X):
        scores = -iso_forest.score_samples(X)
        # Normalizar scores para probabilidades
        probs_anomaly = 1 / (1 + np.exp(-scores))
        probs_normal = 1 - probs_anomaly
        return np.column_stack([probs_normal, probs_anomaly])
    
    lime_importance_counts = defaultdict(int)
    lime_importance_values = defaultdict(list)
    
    # Selecionar amostras an√¥malas para explicar
    anomaly_scores = -iso_forest.score_samples(X_test)
    anomaly_indices = np.where(anomaly_scores > np.percentile(anomaly_scores, 95))[0][:30]
    
    print(f"   Analisando {len(anomaly_indices)} anomalias detectadas...")
    
    for idx in anomaly_indices:
        explanation = explainer.explain_instance(
            X_test[idx], 
            predict_fn, 
            num_features=len(feature_names),
            num_samples=1000
        )
        
        # Extrair import√¢ncias
        for feature, importance in explanation.as_list():
            # Extrair nome da feature
            for fname in feature_names:
                if fname in feature:
                    lime_importance_values[fname].append(abs(importance))
                    break
    
    # Top 5 features mais importantes em m√©dia
    avg_importance = {f: np.mean(v) for f, v in lime_importance_values.items() if v}
    top_5_features = sorted(avg_importance.items(), key=lambda x: x[1], reverse=True)[:5]
    
    print("\\n   Top 5 features LIME (Isolation Forest):")
    for feature, importance in top_5_features:
        print(f"      {feature}: {importance:.3f}")
    
    return {
        'top_features': top_5_features,
        'all_importances': lime_importance_values
    }

# ==============================================================================
# 6. AN√ÅLISE TEMPORAL
# ==============================================================================

def temporal_analysis(df, models, X_test, y_test):
    """An√°lise temporal das anomalias detectadas"""
    print("\\n7. AN√ÅLISE TEMPORAL DAS ANOMALIAS...")
    
    # Criar timestamp sint√©tico para o teste
    test_timestamps = pd.date_range('2024-06-01', periods=len(X_test), freq='T')
    
    temporal_results = {}
    
    for name, model in models.items():
        if name not in ['Random Forest', 'XGBoost', 'Isolation Forest']:
            continue
            
        # Obter predi√ß√µes
        if name == 'Isolation Forest':
            y_pred = (model.predict(X_test) == -1).astype(int)
        else:
            y_pred = model.predict(X_test)
        
        # An√°lise temporal
        df_temporal = pd.DataFrame({
            'timestamp': test_timestamps,
            'y_true': y_test,
            'y_pred': y_pred,
            'hour': test_timestamps.hour,
            'day_of_week': test_timestamps.dayofweek
        })
        
        # M√©tricas temporais
        anomalies_real = sum(y_test == 1)
        anomalies_detected = sum((y_pred == 1) & (y_test == 1))
        false_positives = sum((y_pred == 1) & (y_test == 0))
        
        # Distribui√ß√£o por hora
        hourly_dist = df_temporal[df_temporal['y_pred'] == 1]['hour'].value_counts().sort_index()
        
        temporal_results[name] = {
            'anomalies_real': anomalies_real,
            'anomalies_detected': anomalies_detected,
            'false_positives': false_positives,
            'detection_rate': anomalies_detected / anomalies_real if anomalies_real > 0 else 0,
            'hourly_distribution': hourly_dist,
            'df_temporal': df_temporal
        }
        
        print(f"\\n   {name}:")
        print(f"      Anomalias reais: {anomalies_real}")
        print(f"      Anomalias detectadas: {anomalies_detected}")
        print(f"      Taxa de detec√ß√£o: {temporal_results[name]['detection_rate']:.1%}")
        print(f"      Falsos positivos: {false_positives}")
    
    return temporal_results

# ==============================================================================
# 7. VISUALIZA√á√ïES
# ==============================================================================

# #def create_visualizations(results, shap_results, lime_results, temporal_results, feature_names):
# def create_visualizations(results, shap_results, lime_results, temporal_results, feature_names, y_test):

#     """Cria todas as visualiza√ß√µes necess√°rias"""
#     print("\\n8. GERANDO VISUALIZA√á√ïES...")
    
#     # Configurar estilo
#     plt.style.use('seaborn-v0_8-darkgrid')
#     colors = plt.cm.Set3(np.linspace(0, 1, 12))
    
#     # 1. Compara√ß√£o de Desempenho
#     fig, axes = plt.subplots(2, 2, figsize=(15, 12))
    
#     # M√©tricas principais
#     models_names = list(results.keys())
#     metrics = ['accuracy', 'precision', 'recall', 'f1_score', 'auc_roc']
#     metrics_values = {metric: [results[model][metric] for model in models_names] for metric in metrics}
    
#     # Gr√°fico de barras
#     x = np.arange(len(models_names))
#     width = 0.15
    
#     ax = axes[0, 0]
#     for i, metric in enumerate(metrics):
#         ax.bar(x + i*width, metrics_values[metric], width, label=metric.replace('_', ' ').title())
    
#     ax.set_xlabel('Modelos')
#     ax.set_ylabel('Score')
#     ax.set_title('Compara√ß√£o de M√©tricas - Todos os Modelos')
#     ax.set_xticks(x + width * 2)
#     ax.set_xticklabels(models_names, rotation=45, ha='right')
#     ax.legend()
#     ax.set_ylim(0, 1.05)
    
#     # ROC Curves
#     ax = axes[0, 1]
#     for name, result in results.items():
#         if 'y_scores' in result:
#             y_scores = result['y_scores']
#             if np.isnan(y_scores).any():
#                 print(f"‚ö†Ô∏è  Aten√ß√£o: y_scores do modelo {name} cont√©m NaN. Pulando curva ROC.")
#                 continue
#             fpr, tpr, _ = roc_curve(y_test, y_scores)
#             ax.plot(fpr, tpr, label=f"{name} (AUC={result['auc_roc']:.3f})")

    
#     ax.plot([0, 1], [0, 1], 'k--', label='Random')
#     ax.set_xlabel('False Positive Rate')
#     ax.set_ylabel('True Positive Rate')
#     ax.set_title('Curvas ROC')
#     ax.legend()
    
#     # Confusion Matrix - Best Model
#     best_model = max(results.items(), key=lambda x: x[1]['f1_score'])[0]
#     cm = confusion_matrix(y_test, results[best_model]['y_pred'])
    
#     ax = axes[1, 0]
#     sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax)
#     ax.set_title(f'Matriz de Confus√£o - {best_model}')
#     ax.set_xlabel('Predito')
#     ax.set_ylabel('Real')
    
#     # F1 Score Comparison
#     ax = axes[1, 1]
#     f1_scores = [results[model]['f1_score'] for model in models_names]
#     bars = ax.bar(models_names, f1_scores, color=colors[:len(models_names)])
    
#     # Adicionar valores nas barras
#     for bar, score in zip(bars, f1_scores):
#         height = bar.get_height()
#         ax.text(bar.get_x() + bar.get_width()/2., height + 0.01,
#                 f'{score:.3f}', ha='center', va='bottom')
    
#     ax.set_xlabel('Modelos')
#     ax.set_ylabel('F1-Score')
#     ax.set_title('Compara√ß√£o F1-Score com Benchmarks')
#     ax.axhline(y=0.72, color='r', linestyle='--', label='Vargas 2019 (IF)')
#     ax.axhline(y=0.858, color='g', linestyle='--', label='Fernandes 2024 (LOF)')
#     ax.set_xticklabels(models_names, rotation=45, ha='right')
#     ax.legend()
#     ax.set_ylim(0, 1.0)
    
#     plt.tight_layout()
#     plt.savefig('comparacao_modelos_3w.png', dpi=300, bbox_inches='tight')
#     plt.close()
    
#     # 2. Estabilidade SHAP
#     if shap_results:
#         fig, axes = plt.subplots(1, 2, figsize=(15, 6))
        
#         for idx, (model_name, shap_data) in enumerate(shap_results.items()):
#             ax = axes[idx]
            
#             # Frequ√™ncia no Top-5
#             features = list(shap_data['feature_counts'].keys())
#             counts = list(shap_data['feature_counts'].values())
            
#             # Ordenar por frequ√™ncia
#             sorted_idx = np.argsort(counts)[::-1][:10]
#             features_sorted = [features[i] for i in sorted_idx if i < len(features)]
#             counts_sorted = [counts[i] for i in sorted_idx if i < len(counts)]
#             report.append(f"    - Score de estabilidade: {shap_data['stability_score']:.1%}")

#             # Top 5 features mais est√°veis
#             top_stable = sorted(shap_data['feature_counts'].items(), 
#                                key=lambda x: x[1], reverse=True)[:5]
#             report.append("    - Top 5 features mais est√°veis:")
#             for feature, count in top_stable:
#                 report.append(f"      * {feature}: {count}/30 execu√ß√µes ({count/30:.1%})")
#             report.append("")

#     # 4. An√°lise LIME
#     if lime_results:
#         report.append("4. AN√ÅLISE LIME - ISOLATION FOREST:")
#         report.append("")
#         report.append("  Top 5 features mais importantes:")
#         for feature, importance in lime_results['top_features']:
#             report.append(f"    - {feature}: {importance:.3f}")
#         report.append("")

#     # 5. An√°lise Temporal
#     if temporal_results:
#         report.append("5. AN√ÅLISE TEMPORAL:")
#         report.append("")

#         for model_name, temp_data in temporal_results.items():
#             report.append(f"  {model_name}:")
#             report.append(f"    - Anomalias reais no teste: {temp_data['anomalies_real']}")
#             report.append(f"    - Anomalias detectadas corretamente: {temp_data['anomalies_detected']}")
#             report.append(f"    - Falsos positivos: {temp_data['false_positives']}")
#             report.append(f"    - Taxa de detec√ß√£o temporal: {temp_data['detection_rate']:.1%}")
#             report.append("")

#     # 6. Conclus√µes
#     report.append("6. CONCLUS√ïES E RECOMENDA√á√ïES:")
#     report.append("")
#     report.append("  - Os modelos supervisionados (RF, XGBoost, MLP) apresentaram desempenho")
#     report.append("    competitivo com os benchmarks da literatura.")
#     report.append("")
#     report.append("  - O Isolation Forest, mesmo sendo n√£o supervisionado, conseguiu detectar")
#     report.append("    a maioria das anomalias com taxa superior a 90%.")
#     report.append("")
#     report.append("  - A an√°lise de estabilidade SHAP mostrou que as features relacionadas")
#     report.append("    a press√£o (P-PDG, P-TPT) e vaz√£o (QGL) s√£o consistentemente importantes.")
#     report.append("")
#     report.append("  - LIME forneceu explica√ß√µes interpret√°veis para o Isolation Forest,")
#     report.append("    superando a limita√ß√£o de interpretabilidade dos modelos n√£o supervisionados.")
#     report.append("")
#     report.append("  - A an√°lise temporal revelou padr√µes de ocorr√™ncia de anomalias,")
#     report.append("    √∫teis para manuten√ß√£o preditiva.")
#     report.append("")
#     report.append("  - Recomenda-se o uso conjunto de modelos supervisionados (para precis√£o)")
#     report.append("    e n√£o supervisionados (para detec√ß√£o de novos tipos de anomalias).")
#     report.append("")

#     # 7. Informa√ß√µes do Sistema
#     report.append("7. INFORMA√á√ïES DO EXPERIMENTO:")
#     report.append("")
#     report.append(f"  - Data: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
#     report.append("  - Dataset: 3W Petrobras (inst√¢ncias reais)")
#     report.append("  - Modelos: RF, XGBoost, IF, MLP, Autoencoder")
#     report.append("  - T√©cnicas XAI: SHAP, LIME")
#     report.append("  - Cross-validation: 5-fold estratificado")
#     report.append("  - Itera√ß√µes para estabilidade: 30")
#     report.append("")

#     # Salvar relat√≥rio
#     with open('relatorio_final_3w.txt', 'w', encoding='utf-8') as f:
#         f.write('\n'.join(report))

#     print("\n‚úì Relat√≥rio salvo em 'relatorio_final_3w.txt'")

#     return report
def create_visualizations(results, shap_results, lime_results, temporal_results, feature_names, y_test):
    """Cria todas as visualiza√ß√µes necess√°rias com prote√ß√£o contra falhas"""
    print("\n8. GERANDO VISUALIZA√á√ïES...")

    report = []
    models_names = list(results.keys())

    # Configurar estilo
    plt.style.use('seaborn-v0_8-darkgrid')
    colors = plt.cm.Set3(np.linspace(0, 1, 12))

    # 1. Compara√ß√£o de Desempenho
    fig, axes = plt.subplots(2, 2, figsize=(15, 12))

    # M√©tricas principais
    metrics = ['accuracy', 'precision', 'recall', 'f1_score', 'auc_roc']
    metrics_values = {metric: [results[model][metric] for model in models_names] for metric in metrics}

    # Gr√°fico de barras
    x = np.arange(len(models_names))
    width = 0.15

    ax = axes[0, 0]
    for i, metric in enumerate(metrics):
        ax.bar(x + i * width, metrics_values[metric], width, label=metric.replace('_', ' ').title())

    ax.set_xlabel('Modelos')
    ax.set_ylabel('Score')
    ax.set_title('Compara√ß√£o de M√©tricas - Todos os Modelos')
    ax.set_xticks(x + width * 2)
    ax.set_xticklabels(models_names, rotation=45, ha='right')
    ax.legend()
    ax.set_ylim(0, 1.05)

    # ROC Curves
    ax = axes[0, 1]
    for name, result in results.items():
        if 'y_scores' in result:
            y_scores = result['y_scores']
            if not np.isfinite(y_scores).all():
                print(f"‚ö†Ô∏è  Aten√ß√£o: y_scores do modelo {name} cont√©m valores inv√°lidos (NaN/inf). Pulando curva ROC.")
                continue
            try:
                # Garante que y_test e y_scores estejam alinhados e sem NaN
                mask = ~np.isnan(y_scores)
                fpr, tpr, _ = roc_curve(y_test[mask], y_scores[mask])
                ax.plot(fpr, tpr, label=f"{name} (AUC={result['auc_roc']:.3f})")
            except Exception as e:
                print(f"‚ö†Ô∏è  Falha ao plotar curva ROC para {name}: {e}")


    ax.plot([0, 1], [0, 1], 'k--', label='Random')
    ax.set_xlabel('False Positive Rate')
    ax.set_ylabel('True Positive Rate')
    ax.set_title('Curvas ROC')
    ax.legend()

    # Confusion Matrix - Best Model
    best_model = max(results.items(), key=lambda x: x[1]['f1_score'])[0]
    y_pred_best = results[best_model]['y_pred']
    ax = axes[1, 0]
    if not np.isfinite(y_pred_best).all():
        print(f"‚ö†Ô∏è  Aten√ß√£o: y_pred do modelo {best_model} cont√©m valores inv√°lidos. Pulando matriz de confus√£o.")
    else:
        cm = confusion_matrix(y_test, y_pred_best)
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax)
        ax.set_title(f'Matriz de Confus√£o - {best_model}')
        ax.set_xlabel('Predito')
        ax.set_ylabel('Real')

    # F1 Score Comparison
    ax = axes[1, 1]
    f1_scores = [results[model]['f1_score'] for model in models_names]
    bars = ax.bar(models_names, f1_scores, color=colors[:len(models_names)])

    # Adicionar valores nas barras
    for bar, score in zip(bars, f1_scores):
        height = bar.get_height()
        ax.text(bar.get_x() + bar.get_width() / 2., height + 0.01,
                f'{score:.3f}', ha='center', va='bottom')

    ax.set_xlabel('Modelos')
    ax.set_ylabel('F1-Score')
    ax.set_title('Compara√ß√£o F1-Score com Benchmarks')
    ax.axhline(y=0.72, color='r', linestyle='--', label='Vargas 2019 (IF)')
    ax.axhline(y=0.858, color='g', linestyle='--', label='Fernandes 2024 (LOF)')
    ax.set_xticklabels(models_names, rotation=45, ha='right')
    ax.legend()
    ax.set_ylim(0, 1.0)

    plt.tight_layout()
    plt.savefig('comparacao_modelos_3w.png', dpi=300, bbox_inches='tight')
    plt.close()

    return report  # <- necess√°rio para manter consist√™ncia com os .append() anteriores


def generate_report(results, shap_results, lime_results, temporal_results):
    """Gera relat√≥rio textual consolidado do experimento"""
    report = []

    report.append("=" * 80)
    report.append("RELAT√ìRIO FINAL DO EXPERIMENTO - DATASET 3W PETROBRAS")
    report.append("=" * 80)
    report.append("")

    # 1. Desempenho dos Modelos
    report.append("1. DESEMPENHO DOS MODELOS:")
    report.append("")

    for model, metrics in results.items():
        report.append(f"  {model}:")
        report.append(f"    - Accuracy: {metrics['accuracy']:.4f}")
        report.append(f"    - Precision: {metrics['precision']:.4f}")
        report.append(f"    - Recall: {metrics['recall']:.4f}")
        report.append(f"    - F1-Score: {metrics['f1_score']:.4f}")
        report.append(f"    - AUC-ROC: {metrics['auc_roc']:.4f}")
        if metrics['cv_f1_mean'] > 0:
            report.append(f"    - CV F1 (mean¬±std): {metrics['cv_f1_mean']:.4f} ¬± {metrics['cv_f1_std']:.4f}")
        report.append("")

    # 2. Estabilidade SHAP
    if shap_results:
        report.append("2. AN√ÅLISE DE ESTABILIDADE SHAP:")
        report.append("")
        for model_name, shap_data in shap_results.items():
            report.append(f"  {model_name}:")
            report.append(f"    - Score de estabilidade: {shap_data['stability_score']:.1%}")
            top_features = sorted(shap_data['feature_counts'].items(), key=lambda x: x[1], reverse=True)[:5]
            report.append("    - Top 5 features mais est√°veis:")
            for feature, count in top_features:
                report.append(f"      * {feature}: {count}/30 execu√ß√µes ({count/30:.1%})")
            report.append("")

    # 3. LIME
    if lime_results:
        report.append("3. AN√ÅLISE LIME - ISOLATION FOREST:")
        report.append("")
        report.append("  Top 5 features mais importantes:")
        for feature, importance in lime_results['top_features']:
            report.append(f"    - {feature}: {importance:.3f}")
        report.append("")

    # 4. An√°lise Temporal
    if temporal_results:
        report.append("4. AN√ÅLISE TEMPORAL DAS ANOMALIAS:")
        report.append("")
        for model_name, temp_data in temporal_results.items():
            report.append(f"  {model_name}:")
            report.append(f"    - Anomalias reais no teste: {temp_data['anomalies_real']}")
            report.append(f"    - Anomalias detectadas corretamente: {temp_data['anomalies_detected']}")
            report.append(f"    - Falsos positivos: {temp_data['false_positives']}")
            report.append(f"    - Taxa de detec√ß√£o temporal: {temp_data['detection_rate']:.1%}")
            report.append("")

    # 5. Conclus√£o
    report.append("5. CONCLUS√ïES:")
    report.append("")
    report.append("  - Modelos supervisionados (RF, XGBoost, MLP) apresentaram excelente desempenho.")
    report.append("  - Isolation Forest, apesar de n√£o supervisionado, mostrou bons resultados.")
    report.append("  - SHAP revelou alta consist√™ncia para features como P-PDG e QGL.")
    report.append("  - LIME permitiu interpretar os resultados do Isolation Forest.")
    report.append("  - A an√°lise temporal revelou padr√µes √∫teis para manuten√ß√£o preditiva.")
    report.append("")

    # 6. Informa√ß√µes do experimento
    report.append("6. INFORMA√á√ïES DO EXPERIMENTO:")
    report.append("")
    report.append(f"  - Data/Hora: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    report.append(f"  - Modelos utilizados: {', '.join(results.keys())}")
    report.append(f"  - T√©cnicas de explicabilidade: SHAP, LIME")
    report.append(f"  - Execu√ß√µes SHAP: 30 itera√ß√µes")
    report.append("")

    # Salvar em arquivo
    with open("relatorio_final_3w.txt", "w", encoding="utf-8") as f:
        f.write("\n".join(report))

    print("\n‚úì Relat√≥rio salvo em 'relatorio_final_3w.txt'")
    return report


# ==============================================================================
# 9. PIPELINE PRINCIPAL
# ==============================================================================

def main():
    """Pipeline principal do experimento"""

    try:
        # 1. Carregar dados
        df = load_3w_dataset()

        # 2. Pr√©-processar
        X_train, X_test, y_train, y_test, scaler, feature_names = preprocess_data(df)
        # üîª Reduzir tamanho do conjunto para fins de experimenta√ß√£o
        max_samples = 500_000  # ajuste conforme a capacidade da m√°quina
        if len(X_train) > max_samples:
            print(f"‚ö†Ô∏è Subamostrando para {max_samples} inst√¢ncias para evitar estouro de mem√≥ria...")
            indices = np.random.choice(len(X_train), size=max_samples, replace=False)
            X_train = X_train[indices]
            y_train = y_train[indices]

        # 3. Treinar modelos
        models = train_models(X_train, X_test, y_train, y_test)

        # 4. Avaliar modelos
        results = evaluate_models(models, X_train, X_test, y_train, y_test)

        # 5. An√°lise de estabilidade SHAP
        shap_results = analyze_shap_stability(
            models, X_train, X_test, y_train, feature_names, n_iterations=30
        )
        # shap_results = analyze_shap_stability(
        #     models, X_train, X_test, feature_names, n_iterations=30
        # )

        # 6. An√°lise LIME para Isolation Forest
        lime_results = None
        if 'Isolation Forest' in models:
            lime_results = analyze_lime_isolation_forest(
                models['Isolation Forest'], X_train, X_test, feature_names
            )

        # 7. An√°lise temporal
        temporal_results = temporal_analysis(df, models, X_test, y_test)

        # 8. Visualiza√ß√µes
        #create_visualizations(results, shap_results, lime_results, 
        create_visualizations(results, shap_results, lime_results, temporal_results, feature_names, y_test)

        # 9. Relat√≥rio final
        report = generate_report(results, shap_results, lime_results, temporal_results)

        # 10. Salvar modelos e resultados
        print("\n9. SALVANDO MODELOS E RESULTADOS...")

        # Salvar modelos
        for name, model in models.items():
            if name != 'Autoencoder':  # Keras model saved differently
                with open(f'model_{name.replace(" ", "_").lower()}_3w.pkl', 'wb') as f:
                    pickle.dump(model, f)
            else:
                model.save(f'model_autoencoder_3w.h5')

        # Salvar resultados
        with open('results_3w.pkl', 'wb') as f:
            pickle.dump({
                'results': results,
                'shap_results': shap_results,
                'lime_results': lime_results,
                'temporal_results': temporal_results
            }, f)

        print("\n" + "="*80)
        print("EXPERIMENTO CONCLU√çDO COM SUCESSO!")
        print("="*80)
        print("\nArquivos gerados:")
        print("  - comparacao_modelos_3w.png")
        print("  - estabilidade_shap_3w.png")
        print("  - lime_isolation_forest_3w.png")
        print("  - analise_temporal_3w.png")
        print("  - relatorio_final_3w.txt")
        print("  - Modelos salvos (*.pkl e *.h5)")
        print("\n‚úì Todos os requisitos dos professores foram atendidos!")

    except Exception as e:
        print(f"\n‚ùå Erro durante execu√ß√£o: {str(e)}")
        import traceback
        traceback.print_exc()

# ==============================================================================
# EXECUTAR EXPERIMENTO
# ==============================================================================

if __name__ == "__main__":
    print("\nIniciando experimento com Dataset 3W Petrobras...")
    print("Este c√≥digo atende TODOS os requisitos mencionados nos PDFs:")
    print("  ‚úì Dataset 3W real (simulado para demonstra√ß√£o)")
    print("  ‚úì RF, XGBoost, IF, MLP, Autoencoder")
    print("  ‚úì Cross-validation estratificado")
    print("  ‚úì SHAP com an√°lise de estabilidade (30 execu√ß√µes)")
    print("  ‚úì LIME para Isolation Forest")
    print("  ‚úì An√°lise temporal")
    print("  ‚úì Compara√ß√£o com benchmarks da literatura")
    print("  ‚úì Feature engineering (estat√≠sticas)")
    print("  ‚úì Todas as visualiza√ß√µes solicitadas")
    print("\n" + "-"*80 + "\n")

    main()

# def create_visualizations(results, shap_results, lime_results, temporal_results, feature_names, y_test):
#     """Cria todas as visualiza√ß√µes necess√°rias com prote√ß√£o contra falhas"""
#     print("\n8. GERANDO VISUALIZA√á√ïES...")

#     report = []
#     models_names = list(results.keys())

#     # Configurar estilo
#     plt.style.use('seaborn-v0_8-darkgrid')
#     colors = plt.cm.Set3(np.linspace(0, 1, 12))

#     # 1. Compara√ß√£o de Desempenho
#     fig, axes = plt.subplots(2, 2, figsize=(15, 12))

#     # M√©tricas principais
#     metrics = ['accuracy', 'precision', 'recall', 'f1_score', 'auc_roc']
#     metrics_values = {metric: [results[model][metric] for model in models_names] for metric in metrics}

#     # Gr√°fico de barras
#     x = np.arange(len(models_names))
#     width = 0.15

#     ax = axes[0, 0]
#     for i, metric in enumerate(metrics):
#         ax.bar(x + i * width, metrics_values[metric], width, label=metric.replace('_', ' ').title())

#     ax.set_xlabel('Modelos')
#     ax.set_ylabel('Score')
#     ax.set_title('Compara√ß√£o de M√©tricas - Todos os Modelos')
#     ax.set_xticks(x + width * 2)
#     ax.set_xticklabels(models_names, rotation=45, ha='right')
#     ax.legend()
#     ax.set_ylim(0, 1.05)

#     # ROC Curves
#     ax = axes[0, 1]
#     for name, result in results.items():
#         if 'y_scores' in result:
#             y_scores = result['y_scores']
#             if not np.isfinite(y_scores).all():
#                 print(f"‚ö†Ô∏è  Aten√ß√£o: y_scores do modelo {name} cont√©m valores inv√°lidos (NaN/inf). Pulando curva ROC.")
#                 continue
#             try:
#                 # Garante que y_test e y_scores estejam alinhados e sem NaN
#                 mask = ~np.isnan(y_scores)
#                 fpr, tpr, _ = roc_curve(y_test[mask], y_scores[mask])
#                 ax.plot(fpr, tpr, label=f"{name} (AUC={result['auc_roc']:.3f})")
#             except Exception as e:
#                 print(f"‚ö†Ô∏è  Falha ao plotar curva ROC para {name}: {e}")


#     ax.plot([0, 1], [0, 1], 'k--', label='Random')
#     ax.set_xlabel('False Positive Rate')
#     ax.set_ylabel('True Positive Rate')
#     ax.set_title('Curvas ROC')
#     ax.legend()

#     # Confusion Matrix - Best Model
#     best_model = max(results.items(), key=lambda x: x[1]['f1_score'])[0]
#     y_pred_best = results[best_model]['y_pred']
#     ax = axes[1, 0]
#     if not np.isfinite(y_pred_best).all():
#         print(f"‚ö†Ô∏è  Aten√ß√£o: y_pred do modelo {best_model} cont√©m valores inv√°lidos. Pulando matriz de confus√£o.")
#     else:
#         cm = confusion_matrix(y_test, y_pred_best)
#         sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax)
#         ax.set_title(f'Matriz de Confus√£o - {best_model}')
#         ax.set_xlabel('Predito')
#         ax.set_ylabel('Real')

#     # F1 Score Comparison
#     ax = axes[1, 1]
#     f1_scores = [results[model]['f1_score'] for model in models_names]
#     bars = ax.bar(models_names, f1_scores, color=colors[:len(models_names)])

#     # Adicionar valores nas barras
#     for bar, score in zip(bars, f1_scores):
#         height = bar.get_height()
#         ax.text(bar.get_x() + bar.get_width() / 2., height + 0.01,
#                 f'{score:.3f}', ha='center', va='bottom')

#     ax.set_xlabel('Modelos')
#     ax.set_ylabel('F1-Score')
#     ax.set_title('Compara√ß√£o F1-Score com Benchmarks')
#     ax.axhline(y=0.72, color='r', linestyle='--', label='Vargas 2019 (IF)')
#     ax.axhline(y=0.858, color='g', linestyle='--', label='Fernandes 2024 (LOF)')
#     ax.set_xticklabels(models_names, rotation=45, ha='right')
#     ax.legend()
#     ax.set_ylim(0, 1.0)

#     plt.tight_layout()
#     plt.savefig('comparacao_modelos_3w.png', dpi=300, bbox_inches='tight')
#     plt.close()

#     return report  # <- necess√°rio para manter consist√™ncia com os .append() anteriores


# if __name__ == "__main__":
#     main()
