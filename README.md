# Paper_Final_IA
Trabalho Final da disciplina de IA, Prof Didier, Unifesp

# Explicabilidade e Robustez em Modelos de Detec√ß√£o de Anomalias Industriais

## üìä Vis√£o Geral do Projeto

Este projeto aborda um desafio cr√≠tico na aplica√ß√£o de modelos de Machine Learning (ML) em **ambientes industriais cr√≠ticos**: o "paradoxo da precis√£o". Embora modelos supervisionados, como Random Forest e XGBoost, demonstrem alta precis√£o na detec√ß√£o de anomalias [1], suas explica√ß√µes geradas por m√©todos como SHAP frequentemente apresentam **instabilidade cr√≠tica, chegando a 0% em testes de estabilidade** [1, 2]. Essa inconsist√™ncia compromete a confian√ßa operacional e a aplica√ß√£o pr√°tica, pois a compreens√£o das causas-raiz das anomalias √© t√£o vital quanto sua detec√ß√£o precisa [3, 4].

Propomos um **framework h√≠brido inovador** que integra a alta precis√£o preditiva de modelos supervisionados com a estabilidade interpretativa proporcionada por abordagens n√£o supervisionadas, como o Isolation Forest associado ao m√©todo LIME [3, 5, 6]. Os resultados experimentais demonstram que essa abordagem n√£o apenas mant√©m elevados n√≠veis de precis√£o na detec√ß√£o de anomalias, mas tamb√©m fornece **explica√ß√µes consistentemente est√°veis e confi√°veis**, essenciais para a tomada de decis√µes em opera√ß√µes industriais [7].

## üéØ Contribui√ß√µes Principais

Este trabalho se destaca pelas seguintes contribui√ß√µes:

1.  **Avalia√ß√£o Comparativa de Desempenho**: Estabelecimento de **benchmarks superiores** com modelos supervisionados (Random Forest, XGBoost e MLP), que alcan√ßaram F1-scores acima de 0,98 no 3W Dataset [8-10]. Isso superou significativamente os benchmarks anteriores da literatura, como o F1-score de 0,72 de Vargas (2019) e 0,858 de Fernandes Jr. et al. (2024) [11-14].
2.  **Revela√ß√£o da Instabilidade Explicativa Cr√≠tica**: Demonstra√ß√£o, atrav√©s de 30 execu√ß√µes independentes, da **instabilidade severa das explica√ß√µes SHAP** para modelos supervisionados (Random Forest e XGBoost), com um score de estabilidade de **0,00%** [2, 8, 15, 16]. Essa inconsist√™ncia levanta s√©rias preocupa√ß√µes sobre sua utilidade pr√°tica no diagn√≥stico de causas [4].
3.  **Valida√ß√£o de Explica√ß√µes Est√°veis em Modelos N√£o Supervisionados**: Aplica√ß√£o bem-sucedida do **m√©todo LIME ao Isolation Forest**, demonstrando sua capacidade de fornecer explica√ß√µes mais est√°veis e fisicamente coerentes [8, 17-20].
4.  **Proposi√ß√£o de um Framework H√≠brido**: Desenvolvimento de diretrizes pr√°ticas para combinar a alta precis√£o dos modelos supervisionados (para alertas) com a estabilidade interpretativa dos modelos n√£o supervisionados (para diagn√≥stico de segunda opini√£o), oferecendo uma solu√ß√£o robusta e operacionalmente confi√°vel [5, 6, 21].

## üìö Palavras-chave

Detec√ß√£o de anomalias, explicabilidade, SHAP, manuten√ß√£o preditiva, 3W Dataset [7].

## üìä Dataset Utilizado

A pesquisa utilizou o **3W Dataset**, um **recurso p√∫blico not√°vel fornecido pela Petrobras** [22-24]. Este conjunto de dados re√∫ne 50.913.215 amostras de medi√ß√µes multivariadas de sensores (press√£o, temperatura, vaz√£o) instalados em po√ßos de petr√≥leo offshore [25]. As inst√¢ncias s√£o categorizadas em condi√ß√µes normais e oito classes de anomalias reais [22, 26].

O 3W Dataset apresenta desafios significativos:
*   **Ru√≠do e Valores Ausentes**: Existem 4947 vari√°veis ausentes (31,17%) e 1535 vari√°veis "congeladas" (9,67%) devido a problemas em sensores ou redes de comunica√ß√£o [25, 27].
*   **Desbalanceamento de Classes**: Cont√©m 597 inst√¢ncias normais e 1397 inst√¢ncias an√¥malas, refletindo o desbalanceamento natural em cen√°rios de falha industrial [28].
*   **Natureza Temporal**: Embora os dados sejam originalmente temporais, este estudo optou por uma abordagem de amostras vetoriais independentes para facilitar a an√°lise da explicabilidade [29].

## üõ†Ô∏è Metodologia

### Pr√©-processamento e Engenharia de Atributos
O pipeline de pr√©-processamento incluiu [29, 30]:
*   **Descarte de vari√°veis** com alto n√∫mero de valores ausentes ou varia√ß√£o insignificante [31].
*   **Preenchimento de valores ausentes** com a mediana dos atributos [31, 32].
*   **Tratamento de outliers extremos** por clipagem (3 vezes o Intervalo Interquartil - IQR) [31, 32].
*   **Extra√ß√£o de estat√≠sticas simples** de cada s√©rie temporal (m√©dia, desvio padr√£o, m√°ximo e m√≠nimo) [31].
*   **Cria√ß√£o de novas *features*** como m√©dia/desvio padr√£o de press√µes e temperaturas, e raz√µes de press√£o e vaz√£o/press√£o [33, 34].
*   **Padroniza√ß√£o dos dados** com `RobustScaler` (menos sens√≠vel a *outliers*) [33, 34].
*   **Balanceamento de classes** usando `class_weight='balanced'` (Random Forest) e `scale_pos_weight` (XGBoost) [33].
*   **Divis√£o estratificada** em conjuntos de treinamento e teste [33, 35].

### Modelos de Machine Learning Utilizados
Foram empregados os seguintes modelos [36, 37]:
*   **Random Forest**: Modelo de *ensemble* robusto, conhecido pela capacidade de generaliza√ß√£o [36].
*   **XGBoost**: Alternativa supervisionada de alta performance [36].
*   **Isolation Forest**: M√©todo n√£o supervisionado, utilizado como linha de base para compara√ß√£o [36]. Treinado apenas com dados normais [38].
*   **Multilayer Perceptron (MLP)**: Rede neural supervisionada [37].
*   **Autoencoder**: Rede neural sim√©trica n√£o supervisionada, treinada para reconstruir a classe normal [37, 39].

### T√©cnicas de Explicabilidade
*   **SHAP (SHapley Additive exPlanations)**: Aplicado aos modelos supervisionados (Random Forest e XGBoost) para analisar a import√¢ncia dos atributos [40]. A estabilidade foi avaliada com **30 execu√ß√µes independentes** utilizando diferentes sementes aleat√≥rias [40-42].
*   **LIME (Local Interpretable Model-agnostic Explanations)**: Empregado para gerar explica√ß√µes locais para o Isolation Forest, superando sua limita√ß√£o de interpretabilidade [43, 44].

### M√©tricas de Avalia√ß√£o
*   **Desempenho Preditivo**: F1-Score (m√©trica principal para datasets desbalanceados), Precis√£o, Recall e AUC-ROC [43, 45]. A avalia√ß√£o foi realizada com valida√ß√£o cruzada estratificada (5-fold) para modelos supervisionados [45, 46].
*   **Robustez Interpretativa**: Medida pela frequ√™ncia com que os atributos apareceram entre os mais importantes nas 30 execu√ß√µes SHAP [45].

## üöÄ Resultados e Discuss√£o

### Desempenho Preditivo
Os **modelos supervisionados (Random Forest, XGBoost e MLP) estabeleceram um novo patamar de performance** para o 3W Dataset, com F1-scores consistentemente superiores a 0.98 [9, 10]. O Random Forest obteve o melhor resultado com F1-score de **0.9905** e AUC-ROC de **0.9974** [47, 48].

Nosso Isolation Forest replicado, mesmo sendo n√£o supervisionado e beneficiado por um pr√©-processamento robusto, atingiu um F1-score de **0.8912**, superando o benchmark de Vargas (2019) [11, 12, 49]. O Autoencoder falhou neste experimento, com F1-score pr√≥ximo de 0 [49, 50].

### Compara√ß√£o com Benchmarks da Literatura
Os resultados do presente trabalho superam significativamente os marcos importantes da literatura que utilizaram o mesmo dataset [12]:
*   **Vargas et al. (2019)**: F1-score de 0,727 com Isolation Forest [11-14, 24, 51].
*   **Fernandes Jr. et al. (2024)**: F1-score de 0,858 com LOF [11, 12, 14, 22, 52].

### Instabilidade das Explica√ß√µes SHAP
A an√°lise de estabilidade das explica√ß√µes SHAP, realizada em 30 execu√ß√µes independentes, revelou uma **instabilidade completa** [2, 16]. Tanto o Random Forest quanto o XGBoost apresentaram um **score de estabilidade de 0.00%** [2, 20, 49]. Isso significa que as *features* consideradas mais importantes variaram drasticamente a cada execu√ß√£o [2]. Por exemplo, para o Random Forest, a vari√°vel mais frequente apareceu no Top-5 em apenas 10% das execu√ß√µes [15]. Para o XGBoost, nenhuma vari√°vel apareceu mais de uma vez [15].

Essa inconsist√™ncia compromete a confian√ßa no sistema de IA, pois um engenheiro de campo pode receber justificativas diferentes para eventos similares [4]. A instabilidade √© atribu√≠da √† aleatoriedade intr√≠nseca dos modelos de *ensemble*, alta colinearidade entre sensores e granularidade extrema do dataset [4, 16, 53].

### An√°lise de Interpretabilidade com LIME para o Isolation Forest
Em contraste, a an√°lise com LIME para o Isolation Forest forneceu **insights valiosos e explica√ß√µes mais est√°veis** [17, 18]. As cinco *features* mais importantes, com base no valor m√©dio de import√¢ncia, foram [17, 20]:
1.  T-TPT (0.007)
2.  mean_temp (0.007)
3.  T-JUS-CKP (0.004)
4.  pressure_ratio (0.003)
5.  P-TPT (0.002)

Isso sugere que, embora o Isolation Forest tenha desempenho preditivo inferior aos supervisionados, ele pode servir como uma **ferramenta indispens√°vel de auditoria e "segundo par de olhos"**, fornecendo um diagn√≥stico mais ancorado na f√≠sica dos dados quando as explica√ß√µes dos modelos supervisionados s√£o vol√°teis [18, 19].

### Consequ√™ncias Operacionais e Framework H√≠brido
Os resultados confirmam o "paradoxo precis√£o vs. confian√ßa" [5, 18]. Para mitigar o risco da instabilidade do SHAP, prop√µe-se uma abordagem h√≠brida: usar a **alta precis√£o dos modelos supervisionados para gerar alertas**, e empregar um modelo como o **Isolation Forest, auditado com LIME, para fornecer uma segunda opini√£o com explica√ß√µes mais est√°veis e coerentes** para o diagn√≥stico da causa-raiz [5, 6, 54].

## ‚û°Ô∏è Trabalhos Futuros

Este estudo abre diversas avenidas para pesquisas futuras, focando em transformar modelos de alta precis√£o em ferramentas verdadeiramente confi√°veis para manuten√ß√£o preditiva industrial [54]:

*   **Aprofundamento na Instabilidade Explicativa**: Explorar t√©cnicas como a agrega√ß√£o de valores SHAP de m√∫ltiplas execu√ß√µes para gerar explica√ß√µes consolidadas e robustas, ou a regulariza√ß√£o de modelos para for√ßar a consist√™ncia na sele√ß√£o de *features* [6, 55].
*   **Arquiteturas Robustas √† Colinearidade**: Investigar modelos como Redes Neurais com mecanismos de aten√ß√£o (*attention mechanisms*) ou *Graph Neural Networks (GNNs)*, que podem aprender a desambiguar contribui√ß√µes de atributos correlatos [55, 56].
*   **M√©tricas de Estabilidade Explicativa Mais Granulares**: Desenvolver m√©tricas como o "acordo de ranking de import√¢ncia" entre m√∫ltiplas execu√ß√µes [56].
*   **Reincorporar a Dimens√£o Temporal**: Utilizar arquiteturas como Long Short-Term Memory (LSTM) e Transformers para aprimorar a detec√ß√£o de anomalias dependentes de padr√µes sequenciais e revelar a din√¢mica de import√¢ncia das vari√°veis ao longo do tempo [57, 58].
*   **Robustez contra Perturba√ß√µes Adversariais**: Avaliar como ru√≠dos sutis, varia√ß√µes operacionais inesperadas ou ataques deliberados podem influenciar o desempenho preditivo e a estabilidade das explica√ß√µes [58, 59].

## üöÄ Como Executar o Projeto

### Requisitos (Bibliotecas Python)
Certifique-se de ter as seguintes bibliotecas instaladas em seu ambiente Python [60-63]:

```bash
numpy
pandas
scikit-learn
xgboost
shap
lime
matplotlib
seaborn
tensorflow # (Para MLP e Autoencoder)

Voc√™ pode instal√°-las via pip: pip install numpy pandas scikit-learn xgboost shap lime matplotlib seaborn tensorflow
Estrutura do C√≥digo
O c√≥digo principal est√° estruturado em se√ß√µes l√≥gicas
:
1. Carregamento e Prepara√ß√£o dos Dados: load_3w_dataset() e preprocess_data()
.
2. Modelos de Machine Learning: create_autoencoder() e train_models() para Random Forest, XGBoost, Isolation Forest, MLP e Autoencoder
.
3. Avalia√ß√£o e Cross-Validation: evaluate_models()
.
4. An√°lise de Explicabilidade com SHAP e LIME: analyze_shap_stability() e analyze_lime_isolation_forest()
.
5. An√°lise Temporal: temporal_analysis()
.
6. Visualiza√ß√µes: create_visualizations() (gera gr√°ficos comparativos, estabilidade SHAP, etc.)
.
7. Gera√ß√£o de Relat√≥rio: generate_report() (opcional, pode ser adaptada para markdown)
.
Artefatos e Resultados
Os artefatos de modelo treinados (Random Forest, XGBoost, Isolation Forest, MLP e Autoencoder) est√£o dispon√≠veis no reposit√≥rio
.
üìù Informa√ß√µes Adicionais
Para a realiza√ß√£o desta pesquisa, foram utilizados agentes de intelig√™ncia artificial (ChatGPT, Gemini) para auxiliar em tarefas como codifica√ß√£o, fichamento de informa√ß√µes de melhorias e corre√ß√£o textual e formata√ß√£o de refer√™ncias
.
‚úâÔ∏è Contato
‚Ä¢ Rosemeri Borges: rose.jbob@gmail.com
üìÑ Licen√ßa
Este projeto √© licenciado sob a licen√ßa, como o artigo de Fernandes Jr. et al. (2024).
